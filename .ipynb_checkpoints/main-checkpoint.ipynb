{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73d674e",
   "metadata": {},
   "source": [
    "### Contents  \n",
    "**_I. Data preprocessing_**\n",
    "> 1. Read dataset  \n",
    "> 2. Missing values handling\n",
    ">> a) `train.csv`  \n",
    ">> b) `test.csv`\n",
    "> 3. Data manipulation\n",
    ">> a) `Date`  \n",
    ">> b) `IsHoliday`  \n",
    ">> c) `Store`  \n",
    ">> d) `Promotion1`, ... , `Promotion5`\n",
    "> 4. Add new features\n",
    "> 5. Remove not using features  \n",
    "\n",
    "**_II. Modeling_**  \n",
    "> 1. Divide `train.csv` into training data and predicting data\n",
    "> 2. Choose a suitable model\n",
    ">> a) XGBooster  \n",
    ">> b) Random Forest  \n",
    "\n",
    "**_III. Submission_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491ffaf",
   "metadata": {},
   "source": [
    "----\n",
    "# I. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2034d",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "128e1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test = pd.read_csv(\"dataset/test.csv\")\n",
    "submission = pd.read_csv(\"dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfaac",
   "metadata": {},
   "source": [
    "## 2. Missing values handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8a773",
   "metadata": {},
   "source": [
    "### a) `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2685bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c34093",
   "metadata": {},
   "source": [
    "### b) `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4d62391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {\n",
    "    \"Promotion1\":test[\"Promotion1\"].mean(), \"Promotion2\":test[\"Promotion2\"].mean(), \n",
    "    \"Promotion3\":test[\"Promotion3\"].mean(), \"Promotion4\":test[\"Promotion4\"].mean(), \n",
    "    \"Promotion5\":test[\"Promotion5\"].mean()\n",
    "}\n",
    "test = test.fillna(value=means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffd826",
   "metadata": {},
   "source": [
    "## 3. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faea470",
   "metadata": {},
   "source": [
    "### a) `Date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0243e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def date_to_week(date):\n",
    "    day, month, year = map(int, date.split('/'))\n",
    "    t = dt.datetime(year, month, day) - dt.datetime(2010, 2, 5)\n",
    "    return int(t.days // 7)\n",
    "\n",
    "# train\n",
    "train[\"Week\"] = train[\"Date\"].apply(date_to_week)\n",
    "\n",
    "# test\n",
    "test[\"Week\"] = test[\"Date\"].apply(date_to_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7d458",
   "metadata": {},
   "source": [
    "### b) `IsHoliday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "515e1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"IsHoliday\"] = train[\"IsHoliday\"].apply(int)\n",
    "test[\"IsHoliday\"] = test[\"IsHoliday\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b42a4",
   "metadata": {},
   "source": [
    "### c) `Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d2994cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(data=train, columns=[\"Store\"])\n",
    "test = pd.get_dummies(data=test, columns=[\"Store\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62e66f",
   "metadata": {},
   "source": [
    "### d) `Promotion1`, ... , `Promotion5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e0daf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# train\n",
    "scaler = QuantileTransformer(n_quantiles = 6255)\n",
    "\n",
    "scaler.fit(train[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "scaled = scaler.transform(train[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "train[['Scaled_Promotion1','Scaled_Promotion2','Scaled_Promotion3','Scaled_Promotion4','Scaled_Promotion5']] = scaled\n",
    "\n",
    "# test\n",
    "scaler = QuantileTransformer(n_quantiles = 180)\n",
    "\n",
    "scaler.fit(test[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "scaled = scaler.transform(test[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "test[['Scaled_Promotion1','Scaled_Promotion2','Scaled_Promotion3','Scaled_Promotion4','Scaled_Promotion5']] = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aef898",
   "metadata": {},
   "source": [
    "## 4. Add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2c100894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>75.09</td>\n",
       "      <td>3.867</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>75.70</td>\n",
       "      <td>3.911</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>67.87</td>\n",
       "      <td>3.948</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>65.32</td>\n",
       "      <td>4.038</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>64.88</td>\n",
       "      <td>3.997</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6255 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature  Fuel_Price  Unemployment\n",
       "0           42.31       2.572         8.106\n",
       "1           38.51       2.548         8.106\n",
       "2           39.93       2.514         8.106\n",
       "3           46.63       2.561         8.106\n",
       "4           46.50       2.625         8.106\n",
       "...           ...         ...           ...\n",
       "6250        75.09       3.867         8.684\n",
       "6251        75.70       3.911         8.684\n",
       "6252        67.87       3.948         8.684\n",
       "6253        65.32       4.038         8.684\n",
       "6254        64.88       3.997         8.684\n",
       "\n",
       "[6255 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_features = [\"Temperature\",\"Fuel_Price\",\"Unemployment\"]\n",
    "dummy = train[social_features]\n",
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85389a7",
   "metadata": {},
   "source": [
    "## 5. Remove not using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df8eb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['id','Date','Promotion1','Promotion2','Promotion3','Promotion4','Promotion5'])\n",
    "train = train.drop(columns=social_features)\n",
    "\n",
    "test = test.drop(columns=['id','Date','Promotion1','Promotion2','Promotion3','Promotion4','Promotion5'])\n",
    "test = test.drop(columns=social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806e6df",
   "metadata": {},
   "source": [
    "----\n",
    "# II. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f106b",
   "metadata": {},
   "source": [
    "## 1. Divide `train.csv` into training data and for predicting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "78b4e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=[\"Weekly_Sales\"])\n",
    "y_train = train[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9b2dc",
   "metadata": {},
   "source": [
    "## 2. Choose a suitable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "74027679",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684312",
   "metadata": {},
   "source": [
    "### a) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d80b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] => time: 2.21(sec)\n",
      "1501480.0, 1395371.5, ... , 689465.25\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "start_t = time.time()\n",
    "model = XGBRegressor(objective='reg:squarederror', learning_rate=0.1, max_depth = 4, n_estimators = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(test)\n",
    "predictions[\"XGBoost\"] = prediction\n",
    "\n",
    "print(f\"[XGBoost] => time: {round(time.time() - start_t, 2)}(sec)\")\n",
    "print(f\"{prediction[0]}, {prediction[1]}, ... , {prediction[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83f84c",
   "metadata": {},
   "source": [
    "### b) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "869d49ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] => time: 3.2(sec)\n",
      "1591366.1142000002, 1509533.3007000005, ... , 753477.0894999998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "start_t = time.time()\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(test)\n",
    "predictions[\"RandomForest\"] = prediction\n",
    "\n",
    "print(f\"[RandomForest] => time: {round(time.time() - start_t, 2)}(sec)\")\n",
    "print(f\"{prediction[0]}, {prediction[1]}, ... , {prediction[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a880c",
   "metadata": {},
   "source": [
    "----\n",
    "# III. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3cf6f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "def name(integer):\n",
    "    return str(integer).zfill(2)\n",
    "    \n",
    "savetime = datetime.datetime.now()\n",
    "folder = \"-\".join(map(name, [savetime.year, savetime.month, savetime.day]))\n",
    "sub_folder = name(savetime.hour) + '：' + name(savetime.minute) + '：' + name(savetime.second)\n",
    "\n",
    "for model in predictions:\n",
    "    submission[\"Weekly_Sales\"] = predictions[model]\n",
    "    os.makedirs(f\"dataset/submissions/{folder}/{sub_folder}\", exist_ok=True)\n",
    "    submission.to_csv(f\"dataset/submissions/{folder}/{sub_folder}/{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af93dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
